{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ee84240-8e67-4b3f-b135-3dbafd84c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcp_project_id = \"fleet-pillar-408114\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc86baf9-3df2-4053-a434-0b633a5dcdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import translate_v3beta1 as translate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e1956b-565b-45fa-8f0b-55e14af68b94",
   "metadata": {},
   "source": [
    "## Create a Service Account:\n",
    "\n",
    "In the Cloud Console, navigate to \"IAM & Admin\" > \"Service accounts.\"\n",
    "Click \"Create Service Account.\"\n",
    "Enter a name for service account, select the role(s) that service account needs (Cloud Translation API Editor, Dataplex Storage Data Writer, Storage Object Admin), and click \"Continue.\"\n",
    "\n",
    "### Generate Key:\n",
    "After creating the service account, click on it in the \"Service accounts\" page.\n",
    "Navigate to the \"Keys\" tab.\n",
    "Click on \"Add Key\" and choose \"JSON.\" This will download a JSON key file containing the necessary credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1092b44-b7a1-48cb-9b94-53e406005af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# give path to json key file\n",
    "\n",
    "credential_path = \"fleet-pillar-408114-fe78fbda4a81.json\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credential_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f608f2-bf24-4475-ab82-07d553c1619e",
   "metadata": {},
   "source": [
    "## Download the dataset and save in local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8218600-72d8-466d-b090-aaab7ee2ef98",
   "metadata": {},
   "source": [
    "### batch translate doesnt support csv, so convert to xlsx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b40ba-1e38-4e59-af0e-1e0df3320e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_csv_to_xlsx(input_folder, output_folder):\n",
    "    # Ensure output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate through each folder in the main folder\n",
    "    for folder_name in os.listdir(input_folder):\n",
    "        folder_path = os.path.join(input_folder, folder_name)\n",
    "\n",
    "        # Check if it is a directory\n",
    "        if os.path.isdir(folder_path):\n",
    "            # Iterate through each CSV file in the subfolder\n",
    "            for csv_file in os.listdir(folder_path):\n",
    "                if csv_file.endswith('.csv'):\n",
    "                    csv_path = os.path.join(folder_path, csv_file)\n",
    "\n",
    "                    # Read CSV file using pandas\n",
    "                    df = pd.read_csv(csv_path)\n",
    "\n",
    "                    # Create Excel file name\n",
    "                    xlsx_file = os.path.splitext(csv_file)[0] + '.xlsx'\n",
    "                    xlsx_path = os.path.join(output_folder, folder_name, xlsx_file)\n",
    "\n",
    "                    # Save DataFrame as Excel\n",
    "                    df.to_excel(xlsx_path, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify the main folder containing subfolders with CSV files\n",
    "    main_folder = \"data\"\n",
    "\n",
    "    # Specify the output folder for Excel files\n",
    "    output_folder = \"data_xlsx\"\n",
    "\n",
    "    # Convert CSV to Excel\n",
    "    convert_csv_to_xlsx(main_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c5e69-b992-471d-b755-a7325c6ce290",
   "metadata": {},
   "source": [
    "### Go to cloud storage and create two buckets, one for storing input dataset and one to save output of dataset\n",
    "\n",
    "upload the downloaded dataset to input bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290f2719-f605-4dbb-8e44-341333784bec",
   "metadata": {},
   "source": [
    "## Translate documents (batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76da4a70-40b3-4893-a7c1-b4c39cbf715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import translate_v3beta1 as translate\n",
    "\n",
    "def batch_translate_document(input_uri, output_uri, project_id, timeout: int = 180,) -> translate.BatchTranslateDocumentResponse:\n",
    "    \"\"\"Batch translate documents.\n",
    "    Args:\n",
    "        input_uri: Google Cloud Storage location of the input document.\n",
    "        output_uri: Google Cloud Storage location of the output document.\n",
    "        project_id: The GCP project ID.\n",
    "        timeout: The timeout for this request.\n",
    "    Returns:\n",
    "        Translated document response\n",
    "    \"\"\"\n",
    "    \n",
    "    client = translate.TranslationServiceClient()\n",
    "\n",
    "    location = \"us-central1\"\n",
    "\n",
    "    # Google Cloud Storage location for the source input. This can be a single file\n",
    "    # (for example, ``gs://translation-test/input.docx``) or a wildcard\n",
    "    # (for example, ``gs://translation-test/*``).\n",
    "    # Supported file types: https://cloud.google.com/translate/docs/supported-formats\n",
    "    gcs_source = {\"input_uri\": input_uri}\n",
    "\n",
    "    batch_document_input_configs = {\n",
    "        \"gcs_source\": gcs_source,\n",
    "    }\n",
    "    gcs_destination = {\"output_uri_prefix\": output_uri}\n",
    "    batch_document_output_config = {\"gcs_destination\": gcs_destination}\n",
    "    parent = f\"projects/{project_id}/locations/{location}\"\n",
    "\n",
    "    operation = client.batch_translate_document(\n",
    "        request={\n",
    "            \"parent\": parent,\n",
    "            \"source_language_code\": \"en-US\",\n",
    "            \"target_language_codes\": [\"hi\"],   # language to convert to\n",
    "            \"input_configs\": [batch_document_input_configs],\n",
    "            \"output_config\": batch_document_output_config,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"Waiting for operation to complete...\")\n",
    "    response = operation.result(timeout)\n",
    "    \n",
    "    print(f\"Total Pages: {response.total_pages}\")\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2230d105-a537-46b8-9b85-da6f1183623c",
   "metadata": {},
   "source": [
    "#### call the function with paths of google cloud storage folders test, train, val and path of output storage folders to store them\n",
    "\n",
    "#### it will probably show timeout error, but after sometime the ouput folder will get populated within the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd722a6-215a-4ecc-bdd7-2dfbafea07bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_translate_document(input_uri= \"gs://mmlu/data/train/*\",\n",
    "    output_uri= \"gs://mmlu_output/data/train/\",\n",
    "    project_id= gcp_project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea893cd-5f57-4537-882f-0b4ae8ba63f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_translate_document(input_uri= \"gs://mmlu/data/train/*\",\n",
    "    output_uri= \"gs://mmlu_output/data/train/\",\n",
    "    project_id= gcp_project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4bdae9-e622-45d2-85a3-c6791a03d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_translate_document(input_uri= \"gs://mmlu/data/train/*\",\n",
    "    output_uri= \"gs://mmlu_output/data/train/\",\n",
    "    project_id= gcp_project_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
